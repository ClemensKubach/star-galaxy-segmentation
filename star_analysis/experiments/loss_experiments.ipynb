{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n",
      "/home/kubach/project_sync/star_analysis\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "import os\n",
    "os.chdir(\"/home/kubach/project_sync/star_analysis\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from star_analysis.model.types import ModelTypes\n",
    "from star_analysis.runner.sdss_runner import SdssRunner\n",
    "from star_analysis.data.augmentations import Augmentations\n",
    "from star_analysis.runner.sdss_runner import SdssRunConfig, SdssModelConfig\n",
    "from star_analysis.model.neural_networks.losses.types import LossType\n",
    "from star_analysis.runner.run import Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SdssRunner(project_name=\"sdss-losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config0 = SdssRunConfig(\n",
    "    model_config=SdssModelConfig(\n",
    "        learning_rate=1e-4,\n",
    "        batch_size=80,\n",
    "        model_type=ModelTypes.UNET,\n",
    "        loss_type=LossType.MSE\n",
    "    ),\n",
    "    augmentation=Augmentations.NONE,\n",
    "    shuffle_train=True\n",
    ")\n",
    "\n",
    "run_config1 = copy.deepcopy(run_config0)\n",
    "run_config1.model_config.loss_type = LossType.DICE\n",
    "\n",
    "run_config2 = copy.deepcopy(run_config0)\n",
    "run_config2.model_config.loss_type = LossType.DA_DICE\n",
    "\n",
    "run_config3 = copy.deepcopy(run_config0)\n",
    "run_config3.model_config.loss_type = LossType.FOCAL\n",
    "\n",
    "run_config4 = copy.deepcopy(run_config0)\n",
    "run_config4.model_config.loss_type = LossType.DA_FOCAL\n",
    "\n",
    "configs = [run_config0, run_config1, run_config2, run_config3, run_config4]\n",
    "runs = [Run(config) for config in configs]\n",
    "\n",
    "for run in runs:\n",
    "    runner.add_run(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023-06-28 20:03:16,951] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "[INFO][2023-06-28 20:03:35,386] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "[INFO][2023-06-28 20:03:53,908] rank_zero.py:_info:48: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "[INFO][2023-06-28 20:03:53,909] rank_zero.py:_info:48: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "[INFO][2023-06-28 20:03:53,910] rank_zero.py:_info:48: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:03:53,910] rank_zero.py:_info:48: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:03:54,106] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "[INFO][2023-06-28 20:04:11,964] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "[INFO][2023-06-28 20:04:30,359] rank_zero.py:_info:48: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "[INFO][2023-06-28 20:04:30,360] rank_zero.py:_info:48: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "[INFO][2023-06-28 20:04:30,361] rank_zero.py:_info:48: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:04:30,361] rank_zero.py:_info:48: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:04:30,560] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "[INFO][2023-06-28 20:04:48,558] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "[INFO][2023-06-28 20:05:06,271] rank_zero.py:_info:48: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "[INFO][2023-06-28 20:05:06,272] rank_zero.py:_info:48: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "[INFO][2023-06-28 20:05:06,272] rank_zero.py:_info:48: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:05:06,273] rank_zero.py:_info:48: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:05:06,465] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "[INFO][2023-06-28 20:05:25,075] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "[INFO][2023-06-28 20:05:43,389] rank_zero.py:_info:48: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "[INFO][2023-06-28 20:05:43,390] rank_zero.py:_info:48: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "[INFO][2023-06-28 20:05:43,391] rank_zero.py:_info:48: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:05:43,392] rank_zero.py:_info:48: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:05:43,589] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "[INFO][2023-06-28 20:06:01,496] image_downloader.py:download_exact:62: Downloading 8162 6 0080\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "[INFO][2023-06-28 20:06:19,420] rank_zero.py:_info:48: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "[INFO][2023-06-28 20:06:19,421] rank_zero.py:_info:48: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "[INFO][2023-06-28 20:06:19,421] rank_zero.py:_info:48: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:06:19,422] rank_zero.py:_info:48: HPU available: False, using: 0 HPUs\n",
      "[INFO][2023-06-28 20:06:19,531] image_downloader.py:download:46: Downloading 8162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run already built. Reusing existing build.\n",
      "Found 947 data/label pairs\n",
      "Found 1 data/label pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[INFO][2023-06-28 20:06:40,740] cuda.py:set_nvidia_flags:58: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name         | Type    | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn      | MseLoss | 0     \n",
      "1 | architecture | Unet    | 14.3 M\n",
      "-----------------------------------------\n",
      "14.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.339    Total estimated model params size (MB)\n",
      "[INFO][2023-06-28 20:06:40,744] model_summary.py:summarize:82: \n",
      "  | Name         | Type    | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn      | MseLoss | 0     \n",
      "1 | architecture | Unet    | 14.3 M\n",
      "-----------------------------------------\n",
      "14.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.339    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d97dcd79ee04f6fa027c8d9288edae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from star_analysis.runner.runner import TuningModes\n",
    "from star_analysis.runner.run import TrainerConfig\n",
    "\n",
    "results = runner.tune(\n",
    "    mode=TuningModes.ITERATIVE,\n",
    "    runs=runs,\n",
    "    trainer_config=TrainerConfig(\n",
    "        logger=runner.logger,\n",
    "        max_epochs=10,\n",
    "    )\n",
    ")\n",
    "run_results = zip(runs, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, result_best = max(run_results, key=lambda x: x[1][f'{x[0].id}/test_f1'])\n",
    "print(f\"Best run, {best_run.name}, achieved {best_run[f'{best_run.id}/test_f1']} test_f1\")\n",
    "\n",
    "for i, (run, result) in enumerate(run_results):\n",
    "    print(f\"Run {run.id}, {run.name}, achieved {result[f'{run.id}/test_f1']} test_f1\")\n",
    "\n",
    "runner.save_model(best_run.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.config.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star_analysis",
   "language": "python",
   "name": "star_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
